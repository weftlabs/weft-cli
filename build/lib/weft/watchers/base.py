"""Base watcher class for all agent watchers.

Provides the core polling loop, file monitoring, and error handling
that all agent watchers inherit.
"""

import logging
import signal
import time
from abc import ABC, abstractmethod
from datetime import UTC, datetime
from pathlib import Path

from weft.audit.hashing import sha256_hash
from weft.code.applier import PatchApplier
from weft.code.models import CodeArtifact
from weft.code.parser import has_code_patches, parse_code_from_markdown
from weft.constants import DEFAULT_POLL_INTERVAL
from weft.queue.file_ops import (
    list_pending_prompts,
    mark_processed,
    read_prompt,
    write_result,
)
from weft.queue.models import PromptTask, ResultTask
from weft.utils.project import get_project_root

logger = logging.getLogger(__name__)


class BaseWatcher(ABC):
    def __init__(
        self,
        feature_id: str,
        agent_id: str,
        ai_history_path: Path,
        poll_interval: int = DEFAULT_POLL_INTERVAL,
    ):
        self.feature_id = feature_id
        self.agent_id = agent_id
        self.ai_history_path = ai_history_path
        self.poll_interval = poll_interval

        self.agent_dir = ai_history_path / feature_id / agent_id
        self._running = False
        self._original_sigint_handler = None
        self._original_sigterm_handler = None

        # Setup signal handlers
        self._setup_signal_handlers()

        logger.info(f"Initialized watcher: {agent_id} for {feature_id}")

    @property
    def is_running(self) -> bool:
        return self._running

    @abstractmethod
    def process_prompt(self, prompt_task: PromptTask) -> str:
        pass

    def post_process_result(self, output_text: str, prompt_task: PromptTask) -> CodeArtifact | None:
        # Check if output contains code patches
        if not has_code_patches(output_text):
            logger.debug("No code patches found in output")
            return None

        # Extract patches
        patches = parse_code_from_markdown(output_text)
        if not patches:
            return None

        logger.info(f"Extracted {len(patches)} code patch(es) from output")

        # Get worktree path
        try:
            worktree_path = self._get_worktree_path()
        except Exception as e:
            logger.error(f"Cannot get worktree path: {e}")
            logger.warning("Skipping code patch application")
            return None

        if not worktree_path.exists():
            logger.error(f"Worktree does not exist: {worktree_path}")
            logger.warning("Skipping code patch application")
            return None

        # Apply patches
        try:
            applier = PatchApplier(worktree_path)
            artifact = CodeArtifact(
                patches=patches,
                summary=f"Code generated by {self.agent_id}",
                metadata={
                    "agent_id": self.agent_id,
                    "feature_id": self.feature_id,
                },
            )
            apply_results = applier.apply_artifact(artifact)

            # Log results
            success_count = sum(1 for r in apply_results if r.success)
            failure_count = len(apply_results) - success_count

            logger.info(f"Applied patches: {success_count} succeeded, {failure_count} failed")

            # Log any errors or warnings
            for result in apply_results:
                if result.error:
                    logger.error(f"Patch error for {result.file_path}: {result.error}")
                elif result.warning:
                    logger.warning(f"Patch warning for {result.file_path}: {result.warning}")

            return artifact

        except Exception:
            logger.exception("Failed to apply code patches")
            return None

    def _get_worktree_path(self) -> Path:
        # Try CODE_REPO_PATH environment variable first (for Docker containers)
        import os

        code_repo_path = os.getenv("WEFT_CODE_REPO_PATH") or os.getenv("CODE_REPO_PATH")

        # Fall back to project root discovery (local development) if not in Docker
        project_root = Path(code_repo_path) if code_repo_path else get_project_root()

        worktree_path = project_root / "worktrees" / self.feature_id
        return worktree_path

    def start(self) -> None:
        self._running = True
        logger.info(f"Starting watcher {self.agent_id} for {self.feature_id}")
        logger.info(f"Watching: {self.agent_dir / 'in'}")
        logger.info(f"Poll interval: {self.poll_interval}s")

        while self._running:
            try:
                self._process_pending_prompts()
            except Exception as e:
                logger.error(f"Error in watch loop: {e}", exc_info=True)

            time.sleep(self.poll_interval)

        logger.info(f"Stopped watcher {self.agent_id}")

    def stop(self) -> None:
        logger.info(f"Stopping watcher {self.agent_id}...")
        self._running = False

    def _setup_signal_handlers(self) -> None:
        # Store original handlers
        self._original_sigint_handler = signal.signal(signal.SIGINT, self._signal_handler)
        self._original_sigterm_handler = signal.signal(signal.SIGTERM, self._signal_handler)

    def _signal_handler(self, signum: int, frame) -> None:
        logger.info(f"Received signal {signum}, shutting down...")
        self.stop()

    def _process_pending_prompts(self) -> None:
        pending = list_pending_prompts(self.agent_dir)

        if not pending:
            return

        logger.info(f"Found {len(pending)} pending prompt(s)")

        for prompt_file in pending:
            try:
                self._process_single_prompt(prompt_file)
            except Exception as e:
                logger.error(
                    f"Failed to process {prompt_file.name}: {e}",
                    exc_info=True,
                )
                # Write error result
                self._write_error_result(prompt_file, str(e))
                # Mark as processed anyway to prevent infinite retry
                try:
                    mark_processed(prompt_file)
                except Exception as mark_error:
                    logger.error(f"Failed to mark as processed: {mark_error}")

    def _process_single_prompt(self, prompt_file: Path) -> None:
        logger.info(f"Processing: {prompt_file.name}")

        # Read prompt
        prompt_task = read_prompt(prompt_file)
        prompt_hash = sha256_hash(prompt_task.prompt_text)

        # Process with subclass implementation
        start_time = time.time()
        output_text = self.process_prompt(prompt_task)
        duration = time.time() - start_time

        output_hash = sha256_hash(output_text)

        logger.info(
            f"Generated output in {duration:.2f}s "
            f"(prompt: {prompt_hash[:8]}, output: {output_hash[:8]})"
        )

        # Post-process result to extract and apply code patches
        code_artifact = self.post_process_result(output_text, prompt_task)

        # Create result with audit trail
        result = ResultTask(
            feature_id=self.feature_id,
            agent_id=self.agent_id,
            output_text=output_text,
            prompt_hash=prompt_hash,
            output_hash=output_hash,
            timestamp=datetime.now(UTC),
            code_artifact=code_artifact,
            conversation_id=prompt_task.conversation_id,
        )

        # Write result
        result_path = write_result(
            self.ai_history_path,
            self.feature_id,
            self.agent_id,
            result,
        )

        logger.info(f"Wrote result: {result_path.name}")

        # Mark prompt as processed
        mark_processed(prompt_file)
        logger.info(f"Marked processed: {prompt_file.name}")

    def _write_error_result(self, prompt_file: Path, error_message: str) -> None:
        try:
            result = ResultTask(
                feature_id=self.feature_id,
                agent_id=self.agent_id,
                output_text=f"ERROR: {error_message}",
                prompt_hash="error",
                output_hash="error",
                timestamp=datetime.now(UTC),
            )

            result_path = write_result(
                self.ai_history_path,
                self.feature_id,
                self.agent_id,
                result,
            )

            logger.info(f"Wrote error result: {result_path.name}")
        except Exception as e:
            logger.error(f"Failed to write error result: {e}", exc_info=True)
